{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb1fa562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5388947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train = True, download= True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"\", train = False, download= True, transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6406be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size = 32)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "637c8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 180\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 1024)\n",
    "        self.fc5 = nn.Linear(1024, 1024)\n",
    "        self.fc6 = nn.Linear(1024, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_h1 = F.relu(self.fc1(x))\n",
    "        output_h2 = F.relu(self.fc2(output_h1))\n",
    "        output_h3 = F.relu(self.fc3(output_h2))\n",
    "        output_h4 = F.relu(self.fc4(output_h3))\n",
    "        output_h5 = F.relu(self.fc5(output_h4))\n",
    "        output = self.fc5(output_h5)\n",
    "        return F.log_softmax(output_h1, dim=1), F.log_softmax(output_h2, dim=1), F.log_softmax(output_h3, dim=1), F.log_softmax(output_h4, dim=1), F.log_softmax(output_h5, dim=1), F.log_softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ec160",
   "metadata": {},
   "source": [
    "# Train a model on CPU and time it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2424fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5464.6211, grad_fn=<AddBackward0>)\n",
      "tensor(1304.3837, grad_fn=<AddBackward0>)\n",
      "tensor(667.2972, grad_fn=<AddBackward0>)\n",
      "tensor(407.7508, grad_fn=<AddBackward0>)\n",
      "tensor(295.3828, grad_fn=<AddBackward0>)\n",
      "tensor(231.5015, grad_fn=<AddBackward0>)\n",
      "tensor(186.1765, grad_fn=<AddBackward0>)\n",
      "tensor(151.0732, grad_fn=<AddBackward0>)\n",
      "tensor(122.6007, grad_fn=<AddBackward0>)\n",
      "tensor(98.7547, grad_fn=<AddBackward0>)\n",
      "tensor(78.8229, grad_fn=<AddBackward0>)\n",
      "tensor(62.1846, grad_fn=<AddBackward0>)\n",
      "tensor(48.1994, grad_fn=<AddBackward0>)\n",
      "tensor(36.4844, grad_fn=<AddBackward0>)\n",
      "tensor(28.5337, grad_fn=<AddBackward0>)\n",
      "tensor(21.2141, grad_fn=<AddBackward0>)\n",
      "tensor(18.8585, grad_fn=<AddBackward0>)\n",
      "tensor(13.8411, grad_fn=<AddBackward0>)\n",
      "tensor(13.4607, grad_fn=<AddBackward0>)\n",
      "tensor(9.6390, grad_fn=<AddBackward0>)\n",
      "tensor(15.5284, grad_fn=<AddBackward0>)\n",
      "tensor(6.9785, grad_fn=<AddBackward0>)\n",
      "tensor(4.0967, grad_fn=<AddBackward0>)\n",
      "tensor(2.8819, grad_fn=<AddBackward0>)\n",
      "tensor(2.1522, grad_fn=<AddBackward0>)\n",
      "tensor(1.6430, grad_fn=<AddBackward0>)\n",
      "tensor(1.3653, grad_fn=<AddBackward0>)\n",
      "tensor(1.1919, grad_fn=<AddBackward0>)\n",
      "tensor(1.0606, grad_fn=<AddBackward0>)\n",
      "tensor(0.9562, grad_fn=<AddBackward0>)\n",
      "tensor(0.8698, grad_fn=<AddBackward0>)\n",
      "tensor(0.7976, grad_fn=<AddBackward0>)\n",
      "tensor(0.7360, grad_fn=<AddBackward0>)\n",
      "tensor(0.6831, grad_fn=<AddBackward0>)\n",
      "tensor(0.6367, grad_fn=<AddBackward0>)\n",
      "tensor(0.5959, grad_fn=<AddBackward0>)\n",
      "tensor(0.5601, grad_fn=<AddBackward0>)\n",
      "tensor(0.5276, grad_fn=<AddBackward0>)\n",
      "tensor(0.4988, grad_fn=<AddBackward0>)\n",
      "tensor(0.4727, grad_fn=<AddBackward0>)\n",
      "tensor(0.4488, grad_fn=<AddBackward0>)\n",
      "tensor(0.4275, grad_fn=<AddBackward0>)\n",
      "tensor(0.4075, grad_fn=<AddBackward0>)\n",
      "tensor(0.3896, grad_fn=<AddBackward0>)\n",
      "tensor(0.3728, grad_fn=<AddBackward0>)\n",
      "tensor(0.3573, grad_fn=<AddBackward0>)\n",
      "tensor(0.3431, grad_fn=<AddBackward0>)\n",
      "tensor(0.3298, grad_fn=<AddBackward0>)\n",
      "tensor(0.3174, grad_fn=<AddBackward0>)\n",
      "tensor(0.3059, grad_fn=<AddBackward0>)\n",
      "tensor(0.2951, grad_fn=<AddBackward0>)\n",
      "tensor(0.2850, grad_fn=<AddBackward0>)\n",
      "tensor(0.2755, grad_fn=<AddBackward0>)\n",
      "tensor(0.2666, grad_fn=<AddBackward0>)\n",
      "tensor(0.2581, grad_fn=<AddBackward0>)\n",
      "tensor(0.2502, grad_fn=<AddBackward0>)\n",
      "tensor(0.2426, grad_fn=<AddBackward0>)\n",
      "tensor(0.2356, grad_fn=<AddBackward0>)\n",
      "tensor(0.2288, grad_fn=<AddBackward0>)\n",
      "tensor(0.2224, grad_fn=<AddBackward0>)\n",
      "tensor(0.2163, grad_fn=<AddBackward0>)\n",
      "tensor(0.2105, grad_fn=<AddBackward0>)\n",
      "tensor(0.2050, grad_fn=<AddBackward0>)\n",
      "tensor(0.1998, grad_fn=<AddBackward0>)\n",
      "tensor(0.1948, grad_fn=<AddBackward0>)\n",
      "tensor(0.1900, grad_fn=<AddBackward0>)\n",
      "tensor(0.1854, grad_fn=<AddBackward0>)\n",
      "tensor(0.1810, grad_fn=<AddBackward0>)\n",
      "tensor(0.1768, grad_fn=<AddBackward0>)\n",
      "tensor(0.1728, grad_fn=<AddBackward0>)\n",
      "tensor(0.1690, grad_fn=<AddBackward0>)\n",
      "tensor(0.1653, grad_fn=<AddBackward0>)\n",
      "tensor(0.1617, grad_fn=<AddBackward0>)\n",
      "tensor(0.1583, grad_fn=<AddBackward0>)\n",
      "tensor(0.1550, grad_fn=<AddBackward0>)\n",
      "tensor(0.1518, grad_fn=<AddBackward0>)\n",
      "tensor(0.1488, grad_fn=<AddBackward0>)\n",
      "tensor(0.1458, grad_fn=<AddBackward0>)\n",
      "tensor(0.1430, grad_fn=<AddBackward0>)\n",
      "tensor(0.1402, grad_fn=<AddBackward0>)\n",
      "tensor(0.1376, grad_fn=<AddBackward0>)\n",
      "tensor(0.1350, grad_fn=<AddBackward0>)\n",
      "tensor(0.1325, grad_fn=<AddBackward0>)\n",
      "tensor(0.1302, grad_fn=<AddBackward0>)\n",
      "tensor(0.1278, grad_fn=<AddBackward0>)\n",
      "tensor(0.1256, grad_fn=<AddBackward0>)\n",
      "tensor(0.1234, grad_fn=<AddBackward0>)\n",
      "tensor(0.1213, grad_fn=<AddBackward0>)\n",
      "tensor(0.1193, grad_fn=<AddBackward0>)\n",
      "tensor(0.1173, grad_fn=<AddBackward0>)\n",
      "tensor(0.1154, grad_fn=<AddBackward0>)\n",
      "tensor(0.1135, grad_fn=<AddBackward0>)\n",
      "tensor(0.1117, grad_fn=<AddBackward0>)\n",
      "tensor(0.1100, grad_fn=<AddBackward0>)\n",
      "tensor(0.1083, grad_fn=<AddBackward0>)\n",
      "tensor(0.1066, grad_fn=<AddBackward0>)\n",
      "tensor(0.1050, grad_fn=<AddBackward0>)\n",
      "tensor(0.1034, grad_fn=<AddBackward0>)\n",
      "tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "tensor(0.1004, grad_fn=<AddBackward0>)\n",
      "tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "tensor(0.0976, grad_fn=<AddBackward0>)\n",
      "tensor(0.0962, grad_fn=<AddBackward0>)\n",
      "tensor(0.0949, grad_fn=<AddBackward0>)\n",
      "tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "tensor(0.0677, grad_fn=<AddBackward0>)\n",
      "tensor(0.0670, grad_fn=<AddBackward0>)\n",
      "tensor(0.0663, grad_fn=<AddBackward0>)\n",
      "tensor(0.0656, grad_fn=<AddBackward0>)\n",
      "tensor(0.0649, grad_fn=<AddBackward0>)\n",
      "tensor(0.0643, grad_fn=<AddBackward0>)\n",
      "tensor(0.0636, grad_fn=<AddBackward0>)\n",
      "tensor(0.0630, grad_fn=<AddBackward0>)\n",
      "tensor(0.0624, grad_fn=<AddBackward0>)\n",
      "tensor(0.0618, grad_fn=<AddBackward0>)\n",
      "tensor(0.0612, grad_fn=<AddBackward0>)\n",
      "tensor(0.0606, grad_fn=<AddBackward0>)\n",
      "tensor(0.0600, grad_fn=<AddBackward0>)\n",
      "tensor(0.0594, grad_fn=<AddBackward0>)\n",
      "tensor(0.0589, grad_fn=<AddBackward0>)\n",
      "tensor(0.0583, grad_fn=<AddBackward0>)\n",
      "tensor(0.0578, grad_fn=<AddBackward0>)\n",
      "tensor(0.0573, grad_fn=<AddBackward0>)\n",
      "tensor(0.0568, grad_fn=<AddBackward0>)\n",
      "tensor(0.0562, grad_fn=<AddBackward0>)\n",
      "tensor(0.0557, grad_fn=<AddBackward0>)\n",
      "tensor(0.0552, grad_fn=<AddBackward0>)\n",
      "tensor(0.0547, grad_fn=<AddBackward0>)\n",
      "tensor(0.0543, grad_fn=<AddBackward0>)\n",
      "tensor(0.0538, grad_fn=<AddBackward0>)\n",
      "tensor(0.0533, grad_fn=<AddBackward0>)\n",
      "tensor(0.0529, grad_fn=<AddBackward0>)\n",
      "tensor(0.0524, grad_fn=<AddBackward0>)\n",
      "tensor(0.0520, grad_fn=<AddBackward0>)\n",
      "tensor(0.0515, grad_fn=<AddBackward0>)\n",
      "tensor(0.0511, grad_fn=<AddBackward0>)\n",
      "tensor(0.0507, grad_fn=<AddBackward0>)\n",
      "tensor(0.0503, grad_fn=<AddBackward0>)\n",
      "tensor(0.0499, grad_fn=<AddBackward0>)\n",
      "tensor(0.0494, grad_fn=<AddBackward0>)\n",
      "tensor(0.0491, grad_fn=<AddBackward0>)\n",
      "tensor(0.0487, grad_fn=<AddBackward0>)\n",
      "tensor(0.0483, grad_fn=<AddBackward0>)\n",
      "tensor(0.0479, grad_fn=<AddBackward0>)\n",
      "tensor(0.0475, grad_fn=<AddBackward0>)\n",
      "tensor(0.0471, grad_fn=<AddBackward0>)\n",
      "tensor(0.0468, grad_fn=<AddBackward0>)\n",
      "tensor(0.0464, grad_fn=<AddBackward0>)\n",
      "tensor(0.0461, grad_fn=<AddBackward0>)\n",
      "tensor(0.0457, grad_fn=<AddBackward0>)\n",
      "tensor(0.0454, grad_fn=<AddBackward0>)\n",
      "tensor(0.0450, grad_fn=<AddBackward0>)\n",
      "tensor(0.0447, grad_fn=<AddBackward0>)\n",
      "tensor(0.0443, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "net = Net()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    total_loss = 0\n",
    "    for data in trainset:  \n",
    "        X, y = data  \n",
    "        net.zero_grad()  \n",
    "        _, _, _, _, _, output = net(X.view(-1,28*28)) \n",
    "        loss = F.nll_loss(output, y)   \n",
    "        total_loss += loss\n",
    "        loss.backward()  \n",
    "        optimizer.step() \n",
    "    print(total_loss)\n",
    "    \n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8ec3536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7308.369572877884, 2.0301026591327456)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_elapsed_cpu = end_time - start_time\n",
    "time_elapsed_cpu, time_elapsed_cpu/(60*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d33ae",
   "metadata": {},
   "source": [
    "# Train a model on GPU and time it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bc40e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a2db0c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5391.7764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1253.5834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(648.2276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(413.0512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(292.0511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(224.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(178.9684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.9149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.6431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(92.0300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(72.1514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.8465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.2286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.9972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.7752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.1928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.5937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.4875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.4095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.5029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.7797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "start_time_gpu = time.time()\n",
    "\n",
    "net = Net().to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    total_loss = 0\n",
    "    for data,target in trainset:  \n",
    "        X, y = data.to(device), target.to(device)  \n",
    "        net.zero_grad()  \n",
    "        _, _, _, _, _, output = net(X.view(-1,28*28)) \n",
    "        loss = F.nll_loss(output, y)   \n",
    "        total_loss += loss\n",
    "        loss.backward()  \n",
    "        optimizer.step() \n",
    "    print(total_loss)\n",
    "    \n",
    "end_time_gpu = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b414d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2313.498715400696, 0.6426385320557488)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_elapsed_gpu = end_time_gpu - start_time_gpu\n",
    "time_elapsed_gpu, time_elapsed_gpu/(60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aefd0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "class_dict = {x:[] for x in range(10)}\n",
    "rand_dim = [c for c in range(10)]\n",
    "class_dict_h4 = {x:[] for x in range(10)}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        X = X.view(-1,784)\n",
    "        _, _, _, _, output_h4, output = net(X)\n",
    "        h4 = output_h4[:, rand_dim]\n",
    "        for (idx1, i), (idx2, x) in zip(enumerate(h4), enumerate(X)):\n",
    "            class_dict_h4[torch.argmax(i).item()].append(x)\n",
    "        for (idx1, i), (idx2, x) in zip(enumerate(output), enumerate(X)):\n",
    "            class_dict[torch.argmax(i).item()].append(x)\n",
    "            if torch.argmax(i) == y[idx1]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    print(\"Accuracy: \", round(correct/total, 3)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
